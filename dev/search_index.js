var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = ESM","category":"page"},{"location":"#ESM","page":"Home","title":"ESM","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for ESM.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [ESM]","category":"page"},{"location":"#ESM.MultiHeadAttention-Tuple{Int64, Int64}","page":"Home","title":"ESM.MultiHeadAttention","text":"Multi-head attention mechanism with rotary embeddings.\n\nMultiHeadAttention(dmodel::Int, nheads::Int)\n\nArguments\n\nd_model::Int: The input and output dimension of the model.\nn_heads::Int: The number of attention heads to use.\n\n\n\n\n\n","category":"method"}]
}
